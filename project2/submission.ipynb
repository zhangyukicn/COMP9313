{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(Transformer):\n",
    "    def __init__(self, outputCols=['id','features', 'label']):\n",
    "        self.outputCols=outputCols\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        return df.select(*self.outputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_features_gen_pipeline(input_descript_col=\"descript\", input_category_col=\"category\", output_feature_col=\"features\", output_label_col=\"label\"):\n",
    "    # white space expression tokenizer\n",
    "    word_tokenizer = Tokenizer(inputCol=input_descript_col, outputCol=\"words\")\n",
    "    #bag of word_count\n",
    "    count_vectors = CountVectorizer(inputCol=\"words\", outputCol=output_feature_col)\n",
    "    # label indexer\n",
    "    label_maker = StringIndexer(inputCol = input_category_col, outputCol = output_label_col)\n",
    "\n",
    "    selector = Selector(outputCols = ['id',output_feature_col, output_label_col])\n",
    "    # build the pipeline\n",
    "    pipeline = Pipeline(stages=[word_tokenizer, count_vectors, label_maker,selector])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_meta_features(training_df, nb_0, nb_1, nb_2, svm_0, svm_1, svm_2):\n",
    "    print(training_df.printSchema())\n",
    "    lr_f1 = []\n",
    "    nb_f1 = []\n",
    "    svm_f1 = []\n",
    "    print(training_df.groupBy('group').count().show())\n",
    "    for i in range(5):\n",
    "        condition = training_df['group'] == i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP9313",
   "language": "python",
   "name": "comp9313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
